{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNSW-NB15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL CODE IS MINE UNLESS OTHERWISE STATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, BatchNormalization, Input, Add, GlobalAveragePooling1D, ReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/AdamWheatman/AI-IDS-Project/raw/refs/heads/main/Code%20Data/Training%20and%20Testing%20Sets.zip\"\n",
    "zip_filename = \"UNSW-NB15.zip\"\n",
    "\n",
    "urllib.request.urlretrieve(url, zip_filename)\n",
    "extract_folder = \"data\"\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "os.remove(zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Training and Testing Sets/UNSW_NB15_training-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoders.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoders = {}\n",
    "\n",
    "for col in [\"proto\", \"service\", \"state\", \"attack_cat\"]:\n",
    "    df[col] = df[col].astype(str).fillna(\"unknown\")\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    df[col] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['id', 'proto', 'service', 'state', 'attack_cat', 'label'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = X.columns.tolist()\n",
    "joblib.dump(feature_names, 'features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Labels to Categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for balancing\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(np.argmax(y_train, axis=1)), y=np.argmax(y_train, axis=1))\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Reshape Data for CNN (Convert to 3D) ----\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters):\n",
    "    shortcut = x\n",
    "    # Apply Convolution, Batch Normalization, and ReLU\n",
    "    x = Conv1D(filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv1D(filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Adjust shortcut to match the shape if needed\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, kernel_size=1, padding='same')(shortcut)\n",
    "\n",
    "    # Add residual connection\n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- CNN Model with Hyperparameter Tuning ----\n",
    "def build_cnn_model(hp):\n",
    "    inputs = Input(shape=(X_train_reshaped.shape[1], 1))\n",
    "    x = Conv1D(hp.Int('filters_1', 64, 256, step=64), kernel_size=3, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    for i in range(hp.Int('num_res_blocks', 1, 3)):\n",
    "        x = residual_block(x, filters=hp.Int(f'filters_res_{i}', 64, 256, step=64))\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(hp.Int('dense_units', 64, 256, step=64), activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[0.001, 0.0001])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning...\n",
      "Reloading Tuner from cnn_tuner\\Enhanced_CNN_IDS\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "print(\"Starting Hyperparameter Tuning...\")\n",
    "tuner = kt.Hyperband(build_cnn_model, objective='val_accuracy', max_epochs=30, directory='cnn_tuner', project_name='Enhanced_CNN_IDS')\n",
    "tuner.search(X_train_reshaped, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Best Model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_cnn_model = tuner.hypermodel.build(best_hps)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1754/1754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 24ms/step - accuracy: 0.9072 - loss: 0.2185 - val_accuracy: 0.9251 - val_loss: 0.1454\n",
      "Epoch 2/30\n",
      "\u001b[1m1754/1754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.9309 - loss: 0.1441 - val_accuracy: 0.9398 - val_loss: 0.1271\n",
      "Epoch 3/30\n",
      "\u001b[1m1754/1754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.9325 - loss: 0.1374 - val_accuracy: 0.9374 - val_loss: 0.1226\n",
      "Epoch 4/30\n",
      "\u001b[1m1754/1754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.9353 - loss: 0.1333 - val_accuracy: 0.9383 - val_loss: 0.1216\n",
      "Epoch 5/30\n",
      "\u001b[1m1754/1754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 24ms/step - accuracy: 0.9352 - loss: 0.1296 - val_accuracy: 0.9443 - val_loss: 0.1121\n",
      "Epoch 6/30\n",
      "\u001b[1m1754/1754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.9390 - loss: 0.1246 - val_accuracy: 0.9439 - val_loss: 0.1157\n",
      "Epoch 7/30\n",
      "\u001b[1m1754/1754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.9376 - loss: 0.1243 - val_accuracy: 0.9390 - val_loss: 0.1240\n",
      "Epoch 8/30\n",
      "\u001b[1m1754/1754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.9403 - loss: 0.1217 - val_accuracy: 0.9351 - val_loss: 0.1254\n",
      "Epoch 9/30\n",
      "\u001b[1m1754/1754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 26ms/step - accuracy: 0.9398 - loss: 0.1216 - val_accuracy: 0.9381 - val_loss: 0.1194\n",
      "Epoch 10/30\n",
      "\u001b[1m1754/1754\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 27ms/step - accuracy: 0.9402 - loss: 0.1192 - val_accuracy: 0.9398 - val_loss: 0.1173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21f0aed1c00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cnn_model.fit(X_train_reshaped, y_train, epochs=30, batch_size=64, validation_split=0.2, class_weight=class_weight_dict, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1096/1096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9415 - loss: 0.1165\n",
      "Test Accuracy: 0.9421\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "loss, accuracy = best_cnn_model.evaluate(X_test_reshaped, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1096/1096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "False Negatives (Attacks misclassified as Benign): 1138\n",
      "False Positives (Benign misclassified as Attacks): 892\n",
      "\n",
      "False Negatives (Missed Attacks) - Example Indices: [ 7 13 21 54 87]\n",
      "False Positives (Incorrectly Flagged Benign) - Example Indices: [ 44  94 107 148 162]\n",
      "[[10277   892]\n",
      " [ 1138 22762]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     11169\n",
      "           1       0.96      0.95      0.96     23900\n",
      "\n",
      "    accuracy                           0.94     35069\n",
      "   macro avg       0.93      0.94      0.93     35069\n",
      "weighted avg       0.94      0.94      0.94     35069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "y_pred = best_cnn_model.predict(X_test_reshaped)\n",
    "\n",
    "# Convert model probabilities to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# False Negative: Attack (1) misclassified as Benign (0)\n",
    "false_negatives = (y_pred_labels == 0) & (y_test_labels == 1)\n",
    "\n",
    "# False Positive: Benign (0) misclassified as Attack (1)\n",
    "false_positives = (y_pred_labels == 1) & (y_test_labels == 0)\n",
    "\n",
    "# Print summary\n",
    "print(f\"False Negatives (Attacks misclassified as Benign): {sum(false_negatives)}\")\n",
    "print(f\"False Positives (Benign misclassified as Attacks): {sum(false_positives)}\")\n",
    "\n",
    "# Show a few misclassified samples\n",
    "misclassified_fn = np.where(false_negatives)[0][:5]  # First 5 false negatives\n",
    "misclassified_fp = np.where(false_positives)[0][:5]  # First 5 false positives\n",
    "\n",
    "print(\"\\nFalse Negatives (Missed Attacks) - Example Indices:\", misclassified_fn)\n",
    "print(\"False Positives (Incorrectly Flagged Benign) - Example Indices:\", misclassified_fp)\n",
    "\n",
    "print(confusion_matrix(y_test_labels, y_pred_labels))\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "best_cnn_model.save('model.h5')\n",
    "best_cnn_model.save('model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
